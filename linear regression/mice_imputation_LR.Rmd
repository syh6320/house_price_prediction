---
title: "homework3"
author: "syh"
date: "May 22, 2017"
output: pdf_document
---

```{r}
# in this version, we use mice to imute missing value
```


```{r}
# get data
raw_train <- read.csv(file = "H:/kaggle/houseprice/data/train.csv",
                      stringsAsFactors = FALSE)

raw_test <- read.csv(file = "H:/kaggle/houseprice/data/test.csv", stringsAsFactors = F)

raw_test$SalePrice <- rep(0,dim(raw_test)[1])

all_data <- rbind(raw_train, raw_test)
```

```{r}
# deal with NA value
# first have a look which columns have NAs
na_sort <- sapply(all_data, function(x){
  sum(is.na(x))
})

na_sort
```
```{r}
# at first we remove columns with na in excess of 5% of all
keep_col <- which(na_sort < dim(all_data)[1] * 0.05)
all_data <- all_data[keep_col]
```


```{r}
# check other columns with NAs
sort(sapply(all_data, function(x){
  sum(is.na(x))
}), decreasing = TRUE)
```


```{r}
# 2. Missingness is caused by that it doesn't exsit
# by mice, to impute them.
library(mice)
# md.pattern(raw_train)
```


```{r}
# convert character to factor
cha_col <- c("MSSubClass", "MSZoning", "Street", "LotShape", "LandContour",
            "Utilities", "LotConfig", "LandSlope", "Neighborhood", "Condition1", "Condition2","BldgType", "HouseStyle", "OverallQual", "OverallCond", "RoofStyle", "RoofMatl","Exterior1st", "Exterior2nd", "MasVnrType", "ExterQual", "ExterCond", "Foundation","BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "Heating","HeatingQC", "CentralAir", "Electrical", "KitchenQual", "Functional", 
"PavedDrive", "MoSold", "SaleType", "SaleCondition")
all_data[cha_col] <- lapply(all_data[cha_col], as.factor)
```

```{r}
# str(all_data)
# summary(all_data)
```

```{r}
# impute nas by mice
im_all_data <- mice(data = all_data, m = 1, method = "cart",printFlag = F)
real_all_data <- complete(im_all_data)
```


```{r}
# check again if there is no missing value
sort(sapply(real_all_data, function(x){sum(is.na(x))}), decreasing = TRUE)
# there isn't missing value any more.
```


```{r}

# record real_all_data data set
write.csv(file = "H:/kaggle/houseprice/data/real_all_data_mice.csv", x = real_all_data)

```

```{r}
#create real_all_data without id
real_all_data <- subset(real_all_data, select = -Id)
```


```{r}
# feature engineering
# how many years are these houses
# train_no_miss$Age <- 2017 - train_no_miss[,"YearBuilt"]

# total Floor square feet + basement
# train_no_miss$tot_Flo_area <- train_no_miss$X1stFlrSF 
                # + train_no_miss$X2ndFlrSF 
                # + train_no_miss$TotalBsmtSF

# how many years house last since repairing
# train_no_miss$rep_yea <- 2017 - train_no_miss$YearRemodAdd
```


```{r}
# transform sale price to more normal, 
# in order to subject to assumptin of linear regression
real_all_data$SalePrice <- log(real_all_data$SalePrice)
```

```{r}
# plot(density(whole_train$SalePrice))
```



```{r}
# train a simple linear regression model first
simple_lm <- lm(SalePrice ~ ., data = real_all_data[c(1:1460),])
                
summary(simple_lm)
```


```{r}
# residual plot
# 1st: residual is unbais and homoscedastic, 
# 2nd: basically, residual is subject to normal distribution which means variacne of error is constant.
# 4th: we know some outlier: 89, 826, 524 high leaverage and high residual
plot(simple_lm)
```


```{r}
# we can draw conclusion that basically underlying relations is linear
# Adjusted R-squared:  0.9358, it seems it's pretty good.
# F-statistic: 83.59, it's not very high, though.
```


```{r}
# scale numerical features
# for purpose of comparing predection power of different features
# num_col <- setdiff(colnames(whole_train),cha_col)
# whole_train[setdiff(num_col,"SalePrice")] <- sapply(whole_train[setdiff(num_col,"SalePrice")], scale)
```


```{r}

# get ind and dep data
dep_data <- real_all_data$SalePrice
# x must be a matrix for glmnet
ind_data <- model.matrix(~., subset(real_all_data, select = -SalePrice))


# split all data into for training model and for prediction
x_model <- ind_data[c(1:dim(raw_train)[1]),]
y_model <- dep_data[c(1:dim(raw_train)[1])]
  

x_pre <- ind_data[-c(1:dim(raw_train)[1]),]

# split training data into train and test
set.seed(1000)
train_ind <- sample(x = 1:dim(x_model)[1], size = dim(x_model)[1] * 0.7)

x_train <- x_model[train_ind,]
y_train <- y_model[train_ind]

x_test <- x_model[-train_ind,]
y_test <- y_model[-train_ind]


```


```{r}
# resolve multicolinearity and select lamda
# we choose different penality methods
library(glmnet)
lasso_lm <- glmnet(x = x_train, y = y_train, alpha = 1)
ridge_lm <- glmnet(x = x_train, y = y_train, alpha = 0)
elnet_lm <- glmnet(x = x_train, y = y_train, alpha = 0.5)
```

```{r}
print(lasso_lm)
```



```{r}
# train 11 models with different alpha, different penalty, ranging from 0 to 1
# by cross validation,default folders are 10
for(i in c(0:10)){
  assign(paste("cvglm", i,sep = ""), 
         cv.glmnet(x = x_test, y = y_test, alpha = i/10,
                  type.measure = "mse", family = "gaussian"))
}
```


```{r}
par(mfrow=c(1,2))
plot(lasso_lm, xvar = "lambda", label = T)
plot(cvglm10)

```


```{r}
# let calculate the mse of these three models
lasso_y <- predict.glmnet(object = lasso_lm, newx = x_test, s = cvglm10$lambda.1se)
mean((y_test - lasso_y)^2)
```


```{r}
par(mfrow=c(1,2))
plot(ridge_lm, xvar = "lambda", label = T)
plot(cvglm0)
```


```{r}
ridge_y <- predict.glmnet(object = ridge_lm, newx = x_test, s = cvglm0$lambda.1se)
mean((y_test - ridge_y)^2)
```


```{r}
elnet_y <- predict.glmnet(object = elnet_lm, newx = x_test, s = cvglm5$lambda.1se)
mean((y_test - elnet_y)^2)
```

```{r}
# it seems that performance of ridge is best
# let's check if there is other elastic net that out-performs it.
```


```{r}
# let choose the optimal lambda from elastic models
cvglm <- list(cvglm0,cvglm1,cvglm2,cvglm3,cvglm4,cvglm5,
           cvglm6,cvglm7,cvglm8,cvglm9,cvglm10
           )
mse <- NULL
for(i in c(1:11)){
  y_pre <- predict.cv.glmnet(object = cvglm[[i]],newx = x_test,
                             s = cvglm[[i]]$lambda.1se)
  mse <- c(mse, mean((y_test - y_pre)^2))
}
```

```{r}
plot(x = c(0:10), y = mse, xlab = "alpha", ylab = "mse")
```

```{r}
# print the model's index with optimal lambda
which.min(mse) - 1
min(mse)
```

```{r}
# we got different model from hoemwork3_1
# use this one on test data

```

```{r}
# use prediction on test data using our optimal model
pre_pri <- predict.cv.glmnet(object = cvglm5, newx = x_pre, 
                             s = cvglm5$lambda.1se)
```


```{r}
result <- data.frame(Id = raw_test$Id, SalePrice = exp(pre_pri))
names(result) <- c("Id", "SalePrice")
```

```{r}
# write result back to csv
write.csv(x = result, file = "H:/kaggle/houseprice/data/submission_2.csv",
          row.names = FALSE)
```

